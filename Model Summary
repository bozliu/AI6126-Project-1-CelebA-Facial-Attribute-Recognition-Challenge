Summary of Model
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 109, 89]           9,408
       BatchNorm2d-2          [-1, 64, 109, 89]             128
              ReLU-3          [-1, 64, 109, 89]               0
         MaxPool2d-4           [-1, 64, 55, 45]               0
            Conv2d-5           [-1, 64, 55, 45]           4,096
       BatchNorm2d-6           [-1, 64, 55, 45]             128
              ReLU-7           [-1, 64, 55, 45]               0
            Conv2d-8           [-1, 64, 55, 45]          36,864
       BatchNorm2d-9           [-1, 64, 55, 45]             128
             ReLU-10           [-1, 64, 55, 45]               0
           Conv2d-11          [-1, 256, 55, 45]          16,384
      BatchNorm2d-12          [-1, 256, 55, 45]             512
           Conv2d-13          [-1, 256, 55, 45]          16,384
      BatchNorm2d-14          [-1, 256, 55, 45]             512
             ReLU-15          [-1, 256, 55, 45]               0
       Bottleneck-16          [-1, 256, 55, 45]               0
           Conv2d-17           [-1, 64, 55, 45]          16,384
      BatchNorm2d-18           [-1, 64, 55, 45]             128
             ReLU-19           [-1, 64, 55, 45]               0
           Conv2d-20           [-1, 64, 55, 45]          36,864
      BatchNorm2d-21           [-1, 64, 55, 45]             128
             ReLU-22           [-1, 64, 55, 45]               0
           Conv2d-23          [-1, 256, 55, 45]          16,384
      BatchNorm2d-24          [-1, 256, 55, 45]             512
             ReLU-25          [-1, 256, 55, 45]               0
       Bottleneck-26          [-1, 256, 55, 45]               0
           Conv2d-27           [-1, 64, 55, 45]          16,384
      BatchNorm2d-28           [-1, 64, 55, 45]             128
             ReLU-29           [-1, 64, 55, 45]               0
           Conv2d-30           [-1, 64, 55, 45]          36,864
      BatchNorm2d-31           [-1, 64, 55, 45]             128
             ReLU-32           [-1, 64, 55, 45]               0
           Conv2d-33          [-1, 256, 55, 45]          16,384
      BatchNorm2d-34          [-1, 256, 55, 45]             512
             ReLU-35          [-1, 256, 55, 45]               0
       Bottleneck-36          [-1, 256, 55, 45]               0
           Conv2d-37          [-1, 128, 55, 45]          32,768
      BatchNorm2d-38          [-1, 128, 55, 45]             256
             ReLU-39          [-1, 128, 55, 45]               0
           Conv2d-40          [-1, 128, 28, 23]         147,456
      BatchNorm2d-41          [-1, 128, 28, 23]             256
             ReLU-42          [-1, 128, 28, 23]               0
           Conv2d-43          [-1, 512, 28, 23]          65,536
      BatchNorm2d-44          [-1, 512, 28, 23]           1,024
           Conv2d-45          [-1, 512, 28, 23]         131,072
      BatchNorm2d-46          [-1, 512, 28, 23]           1,024
             ReLU-47          [-1, 512, 28, 23]               0
       Bottleneck-48          [-1, 512, 28, 23]               0
           Conv2d-49          [-1, 128, 28, 23]          65,536
      BatchNorm2d-50          [-1, 128, 28, 23]             256
             ReLU-51          [-1, 128, 28, 23]               0
           Conv2d-52          [-1, 128, 28, 23]         147,456
      BatchNorm2d-53          [-1, 128, 28, 23]             256
             ReLU-54          [-1, 128, 28, 23]               0
           Conv2d-55          [-1, 512, 28, 23]          65,536
      BatchNorm2d-56          [-1, 512, 28, 23]           1,024
             ReLU-57          [-1, 512, 28, 23]               0
       Bottleneck-58          [-1, 512, 28, 23]               0
           Conv2d-59          [-1, 128, 28, 23]          65,536
      BatchNorm2d-60          [-1, 128, 28, 23]             256
             ReLU-61          [-1, 128, 28, 23]               0
           Conv2d-62          [-1, 128, 28, 23]         147,456
      BatchNorm2d-63          [-1, 128, 28, 23]             256
             ReLU-64          [-1, 128, 28, 23]               0
           Conv2d-65          [-1, 512, 28, 23]          65,536
      BatchNorm2d-66          [-1, 512, 28, 23]           1,024
             ReLU-67          [-1, 512, 28, 23]               0
       Bottleneck-68          [-1, 512, 28, 23]               0
           Conv2d-69          [-1, 128, 28, 23]          65,536
      BatchNorm2d-70          [-1, 128, 28, 23]             256
             ReLU-71          [-1, 128, 28, 23]               0
           Conv2d-72          [-1, 128, 28, 23]         147,456
      BatchNorm2d-73          [-1, 128, 28, 23]             256
             ReLU-74          [-1, 128, 28, 23]               0
           Conv2d-75          [-1, 512, 28, 23]          65,536
      BatchNorm2d-76          [-1, 512, 28, 23]           1,024
             ReLU-77          [-1, 512, 28, 23]               0
       Bottleneck-78          [-1, 512, 28, 23]               0
           Conv2d-79          [-1, 256, 28, 23]         131,072
      BatchNorm2d-80          [-1, 256, 28, 23]             512
             ReLU-81          [-1, 256, 28, 23]               0
           Conv2d-82          [-1, 256, 14, 12]         589,824
      BatchNorm2d-83          [-1, 256, 14, 12]             512
             ReLU-84          [-1, 256, 14, 12]               0
           Conv2d-85         [-1, 1024, 14, 12]         262,144
      BatchNorm2d-86         [-1, 1024, 14, 12]           2,048
           Conv2d-87         [-1, 1024, 14, 12]         524,288
      BatchNorm2d-88         [-1, 1024, 14, 12]           2,048
             ReLU-89         [-1, 1024, 14, 12]               0
       Bottleneck-90         [-1, 1024, 14, 12]               0
           Conv2d-91          [-1, 256, 14, 12]         262,144
      BatchNorm2d-92          [-1, 256, 14, 12]             512
             ReLU-93          [-1, 256, 14, 12]               0
           Conv2d-94          [-1, 256, 14, 12]         589,824
      BatchNorm2d-95          [-1, 256, 14, 12]             512
             ReLU-96          [-1, 256, 14, 12]               0
           Conv2d-97         [-1, 1024, 14, 12]         262,144
      BatchNorm2d-98         [-1, 1024, 14, 12]           2,048
             ReLU-99         [-1, 1024, 14, 12]               0
      Bottleneck-100         [-1, 1024, 14, 12]               0
          Conv2d-101          [-1, 256, 14, 12]         262,144
     BatchNorm2d-102          [-1, 256, 14, 12]             512
            ReLU-103          [-1, 256, 14, 12]               0
          Conv2d-104          [-1, 256, 14, 12]         589,824
     BatchNorm2d-105          [-1, 256, 14, 12]             512
            ReLU-106          [-1, 256, 14, 12]               0
          Conv2d-107         [-1, 1024, 14, 12]         262,144
     BatchNorm2d-108         [-1, 1024, 14, 12]           2,048
            ReLU-109         [-1, 1024, 14, 12]               0
      Bottleneck-110         [-1, 1024, 14, 12]               0
          Conv2d-111          [-1, 256, 14, 12]         262,144
     BatchNorm2d-112          [-1, 256, 14, 12]             512
            ReLU-113          [-1, 256, 14, 12]               0
          Conv2d-114          [-1, 256, 14, 12]         589,824
     BatchNorm2d-115          [-1, 256, 14, 12]             512
            ReLU-116          [-1, 256, 14, 12]               0
          Conv2d-117         [-1, 1024, 14, 12]         262,144
     BatchNorm2d-118         [-1, 1024, 14, 12]           2,048
            ReLU-119         [-1, 1024, 14, 12]               0
      Bottleneck-120         [-1, 1024, 14, 12]               0
          Conv2d-121          [-1, 256, 14, 12]         262,144
     BatchNorm2d-122          [-1, 256, 14, 12]             512
            ReLU-123          [-1, 256, 14, 12]               0
          Conv2d-124          [-1, 256, 14, 12]         589,824
     BatchNorm2d-125          [-1, 256, 14, 12]             512
            ReLU-126          [-1, 256, 14, 12]               0
          Conv2d-127         [-1, 1024, 14, 12]         262,144
     BatchNorm2d-128         [-1, 1024, 14, 12]           2,048
            ReLU-129         [-1, 1024, 14, 12]               0
      Bottleneck-130         [-1, 1024, 14, 12]               0
          Conv2d-131          [-1, 256, 14, 12]         262,144
     BatchNorm2d-132          [-1, 256, 14, 12]             512
            ReLU-133          [-1, 256, 14, 12]               0
          Conv2d-134          [-1, 256, 14, 12]         589,824
     BatchNorm2d-135          [-1, 256, 14, 12]             512
            ReLU-136          [-1, 256, 14, 12]               0
          Conv2d-137         [-1, 1024, 14, 12]         262,144
     BatchNorm2d-138         [-1, 1024, 14, 12]           2,048
            ReLU-139         [-1, 1024, 14, 12]               0
      Bottleneck-140         [-1, 1024, 14, 12]               0
          Conv2d-141          [-1, 512, 14, 12]         524,288
     BatchNorm2d-142          [-1, 512, 14, 12]           1,024
            ReLU-143          [-1, 512, 14, 12]               0
          Conv2d-144            [-1, 512, 7, 6]       2,359,296
     BatchNorm2d-145            [-1, 512, 7, 6]           1,024
            ReLU-146            [-1, 512, 7, 6]               0
          Conv2d-147           [-1, 2048, 7, 6]       1,048,576
     BatchNorm2d-148           [-1, 2048, 7, 6]           4,096
          Conv2d-149           [-1, 2048, 7, 6]       2,097,152
     BatchNorm2d-150           [-1, 2048, 7, 6]           4,096
            ReLU-151           [-1, 2048, 7, 6]               0
      Bottleneck-152           [-1, 2048, 7, 6]               0
          Conv2d-153            [-1, 512, 7, 6]       1,048,576
     BatchNorm2d-154            [-1, 512, 7, 6]           1,024
            ReLU-155            [-1, 512, 7, 6]               0
          Conv2d-156            [-1, 512, 7, 6]       2,359,296
     BatchNorm2d-157            [-1, 512, 7, 6]           1,024
            ReLU-158            [-1, 512, 7, 6]               0
          Conv2d-159           [-1, 2048, 7, 6]       1,048,576
     BatchNorm2d-160           [-1, 2048, 7, 6]           4,096
            ReLU-161           [-1, 2048, 7, 6]               0
      Bottleneck-162           [-1, 2048, 7, 6]               0
          Conv2d-163            [-1, 512, 7, 6]       1,048,576
     BatchNorm2d-164            [-1, 512, 7, 6]           1,024
            ReLU-165            [-1, 512, 7, 6]               0
          Conv2d-166            [-1, 512, 7, 6]       2,359,296
     BatchNorm2d-167            [-1, 512, 7, 6]           1,024
            ReLU-168            [-1, 512, 7, 6]               0
          Conv2d-169           [-1, 2048, 7, 6]       1,048,576
     BatchNorm2d-170           [-1, 2048, 7, 6]           4,096
            ReLU-171           [-1, 2048, 7, 6]               0
      Bottleneck-172           [-1, 2048, 7, 6]               0
AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0
          Linear-174                  [-1, 512]       1,049,088
     BatchNorm1d-175                  [-1, 512]           1,024
         Dropout-176                  [-1, 512]               0
            ReLU-177                  [-1, 512]               0
        fc_block-178                  [-1, 512]               0
          Linear-179                  [-1, 256]         131,328
     BatchNorm1d-180                  [-1, 256]             512
         Dropout-181                  [-1, 256]               0
            ReLU-182                  [-1, 256]               0
        fc_block-183                  [-1, 256]               0
          Linear-184                    [-1, 2]             514
          Linear-185                  [-1, 256]         131,328
     BatchNorm1d-186                  [-1, 256]             512
         Dropout-187                  [-1, 256]               0
            ReLU-188                  [-1, 256]               0
        fc_block-189                  [-1, 256]               0
          Linear-190                    [-1, 2]             514
          Linear-191                  [-1, 256]         131,328
     BatchNorm1d-192                  [-1, 256]             512
         Dropout-193                  [-1, 256]               0
            ReLU-194                  [-1, 256]               0
        fc_block-195                  [-1, 256]               0
          Linear-196                    [-1, 2]             514
          Linear-197                  [-1, 256]         131,328
     BatchNorm1d-198                  [-1, 256]             512
         Dropout-199                  [-1, 256]               0
            ReLU-200                  [-1, 256]               0
        fc_block-201                  [-1, 256]               0
          Linear-202                    [-1, 2]             514
          Linear-203                  [-1, 256]         131,328
     BatchNorm1d-204                  [-1, 256]             512
         Dropout-205                  [-1, 256]               0
            ReLU-206                  [-1, 256]               0
        fc_block-207                  [-1, 256]               0
          Linear-208                    [-1, 2]             514
          Linear-209                  [-1, 256]         131,328
     BatchNorm1d-210                  [-1, 256]             512
         Dropout-211                  [-1, 256]               0
            ReLU-212                  [-1, 256]               0
        fc_block-213                  [-1, 256]               0
          Linear-214                    [-1, 2]             514
          Linear-215                  [-1, 256]         131,328
     BatchNorm1d-216                  [-1, 256]             512
         Dropout-217                  [-1, 256]               0
            ReLU-218                  [-1, 256]               0
        fc_block-219                  [-1, 256]               0
          Linear-220                    [-1, 2]             514
          Linear-221                  [-1, 256]         131,328
     BatchNorm1d-222                  [-1, 256]             512
         Dropout-223                  [-1, 256]               0
            ReLU-224                  [-1, 256]               0
        fc_block-225                  [-1, 256]               0
          Linear-226                    [-1, 2]             514
          Linear-227                  [-1, 256]         131,328
     BatchNorm1d-228                  [-1, 256]             512
         Dropout-229                  [-1, 256]               0
            ReLU-230                  [-1, 256]               0
        fc_block-231                  [-1, 256]               0
          Linear-232                    [-1, 2]             514
          Linear-233                  [-1, 256]         131,328
     BatchNorm1d-234                  [-1, 256]             512
         Dropout-235                  [-1, 256]               0
            ReLU-236                  [-1, 256]               0
        fc_block-237                  [-1, 256]               0
          Linear-238                    [-1, 2]             514
          Linear-239                  [-1, 256]         131,328
     BatchNorm1d-240                  [-1, 256]             512
         Dropout-241                  [-1, 256]               0
            ReLU-242                  [-1, 256]               0
        fc_block-243                  [-1, 256]               0
          Linear-244                    [-1, 2]             514
          Linear-245                  [-1, 256]         131,328
     BatchNorm1d-246                  [-1, 256]             512
         Dropout-247                  [-1, 256]               0
            ReLU-248                  [-1, 256]               0
        fc_block-249                  [-1, 256]               0
          Linear-250                    [-1, 2]             514
          Linear-251                  [-1, 256]         131,328
     BatchNorm1d-252                  [-1, 256]             512
         Dropout-253                  [-1, 256]               0
            ReLU-254                  [-1, 256]               0
        fc_block-255                  [-1, 256]               0
          Linear-256                    [-1, 2]             514
          Linear-257                  [-1, 256]         131,328
     BatchNorm1d-258                  [-1, 256]             512
         Dropout-259                  [-1, 256]               0
            ReLU-260                  [-1, 256]               0
        fc_block-261                  [-1, 256]               0
          Linear-262                    [-1, 2]             514
          Linear-263                  [-1, 256]         131,328
     BatchNorm1d-264                  [-1, 256]             512
         Dropout-265                  [-1, 256]               0
            ReLU-266                  [-1, 256]               0
        fc_block-267                  [-1, 256]               0
          Linear-268                    [-1, 2]             514
          Linear-269                  [-1, 256]         131,328
     BatchNorm1d-270                  [-1, 256]             512
         Dropout-271                  [-1, 256]               0
            ReLU-272                  [-1, 256]               0
        fc_block-273                  [-1, 256]               0
          Linear-274                    [-1, 2]             514
          Linear-275                  [-1, 256]         131,328
     BatchNorm1d-276                  [-1, 256]             512
         Dropout-277                  [-1, 256]               0
            ReLU-278                  [-1, 256]               0
        fc_block-279                  [-1, 256]               0
          Linear-280                    [-1, 2]             514
          Linear-281                  [-1, 256]         131,328
     BatchNorm1d-282                  [-1, 256]             512
         Dropout-283                  [-1, 256]               0
            ReLU-284                  [-1, 256]               0
        fc_block-285                  [-1, 256]               0
          Linear-286                    [-1, 2]             514
          Linear-287                  [-1, 256]         131,328
     BatchNorm1d-288                  [-1, 256]             512
         Dropout-289                  [-1, 256]               0
            ReLU-290                  [-1, 256]               0
        fc_block-291                  [-1, 256]               0
          Linear-292                    [-1, 2]             514
          Linear-293                  [-1, 256]         131,328
     BatchNorm1d-294                  [-1, 256]             512
         Dropout-295                  [-1, 256]               0
            ReLU-296                  [-1, 256]               0
        fc_block-297                  [-1, 256]               0
          Linear-298                    [-1, 2]             514
          Linear-299                  [-1, 256]         131,328
     BatchNorm1d-300                  [-1, 256]             512
         Dropout-301                  [-1, 256]               0
            ReLU-302                  [-1, 256]               0
        fc_block-303                  [-1, 256]               0
          Linear-304                    [-1, 2]             514
          Linear-305                  [-1, 256]         131,328
     BatchNorm1d-306                  [-1, 256]             512
         Dropout-307                  [-1, 256]               0
            ReLU-308                  [-1, 256]               0
        fc_block-309                  [-1, 256]               0
          Linear-310                    [-1, 2]             514
          Linear-311                  [-1, 256]         131,328
     BatchNorm1d-312                  [-1, 256]             512
         Dropout-313                  [-1, 256]               0
            ReLU-314                  [-1, 256]               0
        fc_block-315                  [-1, 256]               0
          Linear-316                    [-1, 2]             514
          Linear-317                  [-1, 256]         131,328
     BatchNorm1d-318                  [-1, 256]             512
         Dropout-319                  [-1, 256]               0
            ReLU-320                  [-1, 256]               0
        fc_block-321                  [-1, 256]               0
          Linear-322                    [-1, 2]             514
          Linear-323                  [-1, 256]         131,328
     BatchNorm1d-324                  [-1, 256]             512
         Dropout-325                  [-1, 256]               0
            ReLU-326                  [-1, 256]               0
        fc_block-327                  [-1, 256]               0
          Linear-328                    [-1, 2]             514
          Linear-329                  [-1, 256]         131,328
     BatchNorm1d-330                  [-1, 256]             512
         Dropout-331                  [-1, 256]               0
            ReLU-332                  [-1, 256]               0
        fc_block-333                  [-1, 256]               0
          Linear-334                    [-1, 2]             514
          Linear-335                  [-1, 256]         131,328
     BatchNorm1d-336                  [-1, 256]             512
         Dropout-337                  [-1, 256]               0
            ReLU-338                  [-1, 256]               0
        fc_block-339                  [-1, 256]               0
          Linear-340                    [-1, 2]             514
          Linear-341                  [-1, 256]         131,328
     BatchNorm1d-342                  [-1, 256]             512
         Dropout-343                  [-1, 256]               0
            ReLU-344                  [-1, 256]               0
        fc_block-345                  [-1, 256]               0
          Linear-346                    [-1, 2]             514
          Linear-347                  [-1, 256]         131,328
     BatchNorm1d-348                  [-1, 256]             512
         Dropout-349                  [-1, 256]               0
            ReLU-350                  [-1, 256]               0
        fc_block-351                  [-1, 256]               0
          Linear-352                    [-1, 2]             514
          Linear-353                  [-1, 256]         131,328
     BatchNorm1d-354                  [-1, 256]             512
         Dropout-355                  [-1, 256]               0
            ReLU-356                  [-1, 256]               0
        fc_block-357                  [-1, 256]               0
          Linear-358                    [-1, 2]             514
          Linear-359                  [-1, 256]         131,328
     BatchNorm1d-360                  [-1, 256]             512
         Dropout-361                  [-1, 256]               0
            ReLU-362                  [-1, 256]               0
        fc_block-363                  [-1, 256]               0
          Linear-364                    [-1, 2]             514
          Linear-365                  [-1, 256]         131,328
     BatchNorm1d-366                  [-1, 256]             512
         Dropout-367                  [-1, 256]               0
            ReLU-368                  [-1, 256]               0
        fc_block-369                  [-1, 256]               0
          Linear-370                    [-1, 2]             514
          Linear-371                  [-1, 256]         131,328
     BatchNorm1d-372                  [-1, 256]             512
         Dropout-373                  [-1, 256]               0
            ReLU-374                  [-1, 256]               0
        fc_block-375                  [-1, 256]               0
          Linear-376                    [-1, 2]             514
          Linear-377                  [-1, 256]         131,328
     BatchNorm1d-378                  [-1, 256]             512
         Dropout-379                  [-1, 256]               0
            ReLU-380                  [-1, 256]               0
        fc_block-381                  [-1, 256]               0
          Linear-382                    [-1, 2]             514
          Linear-383                  [-1, 256]         131,328
     BatchNorm1d-384                  [-1, 256]             512
         Dropout-385                  [-1, 256]               0
            ReLU-386                  [-1, 256]               0
        fc_block-387                  [-1, 256]               0
          Linear-388                    [-1, 2]             514
          Linear-389                  [-1, 256]         131,328
     BatchNorm1d-390                  [-1, 256]             512
         Dropout-391                  [-1, 256]               0
            ReLU-392                  [-1, 256]               0
        fc_block-393                  [-1, 256]               0
          Linear-394                    [-1, 2]             514
          Linear-395                  [-1, 256]         131,328
     BatchNorm1d-396                  [-1, 256]             512
         Dropout-397                  [-1, 256]               0
            ReLU-398                  [-1, 256]               0
        fc_block-399                  [-1, 256]               0
          Linear-400                    [-1, 2]             514
          Linear-401                  [-1, 256]         131,328
     BatchNorm1d-402                  [-1, 256]             512
         Dropout-403                  [-1, 256]               0
            ReLU-404                  [-1, 256]               0
        fc_block-405                  [-1, 256]               0
          Linear-406                    [-1, 2]             514
          Linear-407                  [-1, 256]         131,328
     BatchNorm1d-408                  [-1, 256]             512
         Dropout-409                  [-1, 256]               0
            ReLU-410                  [-1, 256]               0
        fc_block-411                  [-1, 256]               0
          Linear-412                    [-1, 2]             514
          Linear-413                  [-1, 256]         131,328
     BatchNorm1d-414                  [-1, 256]             512
         Dropout-415                  [-1, 256]               0
            ReLU-416                  [-1, 256]               0
        fc_block-417                  [-1, 256]               0
          Linear-418                    [-1, 2]             514
          ResNet-419  [[-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2], [-1, 2]]               0
================================================================
Total params: 29,852,304
Trainable params: 29,852,304
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.44
Forward/backward pass size (MB): 8388374.64
Params size (MB): 113.88
Estimated Total Size (MB): 8388488.96
----------------------------------------------------------------
